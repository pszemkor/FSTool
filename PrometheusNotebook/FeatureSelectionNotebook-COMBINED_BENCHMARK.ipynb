{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from random import sample\n",
    "from collections import defaultdict\n",
    "from statistics import median\n",
    "from pandarallel import pandarallel\n",
    "import csv\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE FVL and RES datasets\n",
    "for kind in ['fvl', 'res']:\n",
    "    target='PATIENT'\n",
    "    cases = pd.read_csv('../data/hcl/{}_cases.csv'.format(kind), index_col=0)\n",
    "    cases[target] = 'case'\n",
    "    controls = pd.read_csv(\"../data/hcl/{}_controls.csv\".format(kind), index_col=0)\n",
    "    controls[target] = 'control'\n",
    "\n",
    "    df = pd.concat([cases, controls], ignore_index=True, sort=False)\n",
    "    labels = list(df[target].values)\n",
    "\n",
    "    # remove ABS from dataset\n",
    "    cols = [c for c in df.columns if c.lower()[:3] != 'abs']\n",
    "    df=df[cols]\n",
    "\n",
    "    df = df[df.select_dtypes([np.number]).columns].dropna(axis='columns')\n",
    "    non_na_features = list(df)\n",
    "\n",
    "    df = df[non_na_features]\n",
    "    df[target] = labels\n",
    "    df.to_csv('../data/hcl/{}.csv'.format(kind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iind(matrix, alpha = 0.5):\n",
    "    p = alpha\n",
    "    matrix = matrix[matrix.sum(axis = 1) > 0.0]\n",
    "    s = matrix.values.sum()\n",
    "    if s == 0:\n",
    "        raise Exception('Sum of matrix is equal to 0')\n",
    "    matrix = matrix / s\n",
    "    m1 = matrix.sum(axis = 1)\n",
    "    m2 = matrix.sum(axis = 0)\n",
    "    outer_p = np.outer(m1, m2) \n",
    "    factor = 1 / (p-1)\n",
    "    s = np.divide(np.power(matrix,p),np.power(outer_p,(p-1))).sum().sum()\n",
    "    dividend = np.log(s)\n",
    "    divisor = (np.log(np.sum(np.power(m2,(2-p)))))\n",
    "    return dividend / divisor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out(m_case, m_control, feature_subset, row_num):\n",
    "    a = m_case.iloc[[row_num],feature_subset]\n",
    "    b = m_control.iloc[:,feature_subset]\n",
    "    partial_res = iind(a.append(b, ignore_index=True)) - iind(m_control.iloc[:,feature_subset])\n",
    "    results = []\n",
    "\n",
    "    for i, feature_num in enumerate(feature_subset):\n",
    "        c = feature_subset.copy()\n",
    "        c.remove(feature_num)\n",
    "        a1 = m_case.iloc[[row_num], c]\n",
    "        b1 = m_control.iloc[:, c]\n",
    "        ind = iind(a1.append(b1, ignore_index=True)) - iind(m_control.iloc[:,c])\n",
    "        results.append(ind)\n",
    "    res = np.subtract(np.array([partial_res]),  np.array([results]))\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_iind(m_case, m_control, features_num, row_num, k):\n",
    "    feature_subset = sample(range(0, features_num), k)\n",
    "    try:\n",
    "        results = leave_one_out(m_case,m_control,feature_subset, row_num)\n",
    "    except Exception as e:\n",
    "        results = np.repeat(np.nan, k)\n",
    "\n",
    "    return np.r_[np.array(feature_subset), results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dict(d, labels, title=\"\"):\n",
    "    vals = []\n",
    "    for k,v in d.items():\n",
    "        vals.append((labels[k], v))\n",
    "    vals = list(sorted(vals, key=lambda x: x[1], reverse=True))\n",
    "    vals = list(zip(*vals))\n",
    "    if len(vals) == 0:\n",
    "        print(\"vals = '[]'\")\n",
    "        return\n",
    "    x = list(vals[0])\n",
    "    y = list(vals[1])  \n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.bar(range(len(y)), y, align='center')\n",
    "    plt.xticks(range(len(x)), x, rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(feature_ind_vals, feature_ind_to_name, all_measurements, plot=True):\n",
    "    feature_median = dict()\n",
    "    for feature_ind, vals in feature_ind_vals.items():\n",
    "        median = np.median(vals)\n",
    "        if feature_ind not in all_measurements:\n",
    "            all_measurements[feature_ind] = vals\n",
    "        else:\n",
    "            all_measurements[feature_ind].extend(vals)\n",
    "        feature_median[feature_ind] = median            \n",
    "            \n",
    "    if plot:\n",
    "        plot_dict(feature_median, feature_ind_to_name, \"patient\")\n",
    "        \n",
    "#     imp_list = list(map(lambda x: x[0], sorted(feature_median.items(), key=lambda x: x[1], reverse=True)))\n",
    "\n",
    "    return feature_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_(col, m, m2, features_count, i, k):\n",
    "    return apply_iind(m, m2, features_count, i, k)\n",
    "\n",
    "def collect_statistics(col, feature_ind_vals, k):\n",
    "    control_res = col.tolist()\n",
    "    for row_num, feature_num in enumerate(control_res):\n",
    "        if row_num == k:\n",
    "            break\n",
    "        ind_val = control_res[row_num + k]\n",
    "        if not np.isnan(ind_val):\n",
    "            feature_ind_vals[int(feature_num)].append(ind_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandarallel.initialize(progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feats(k, patient_id, feats):\n",
    "    with open('k{}_patient{}.csv'.format(k,patient_ind),'w') as out:\n",
    "        csv_out=csv.writer(out)\n",
    "        csv_out.writerow(['feat','score'])\n",
    "        for row in feats:\n",
    "            csv_out.writerow(row)\n",
    "            \n",
    "def save_names(feats_to_names):\n",
    "    with open('feat_to_name.csv', 'w') as f:\n",
    "        w = csv.DictWriter(f, feats_to_names.keys())\n",
    "        w.writeheader()\n",
    "        w.writerow(feats_to_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_ind_to_name(m):\n",
    "    feature_ind_to_name = dict()\n",
    "    for i, feature_name in enumerate(m.columns):\n",
    "        feature_ind_to_name[i] = feature_name\n",
    "    save_names(feature_ind_to_name)\n",
    "#     print(feature_ind_to_name)\n",
    "    return feature_ind_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_based(m_cases, m_controls, features_subset_size, iters, subset):\n",
    "    start = time.time()\n",
    "    feature_ind_to_name = collect_ind_to_name(m_cases)\n",
    "    FEATURES_COUNT = m_cases.shape[1]\n",
    "    print('FEATURES COUNT', FEATURES_COUNT)\n",
    "    \n",
    "    all_measurements = dict()\n",
    "    importance_per_patient=dict()\n",
    "    for patient_ind, ind_row in enumerate(m_cases.iterrows()):\n",
    "        # Perform FS algorithm\n",
    "        print(\"Starting for k = \", features_subset_size, \", patient = \", ind_row[0],  \"(i={})...\".format(patient_ind))\n",
    "        d = pd.DataFrame(-1, index=np.arange(2*features_subset_size), columns=[i+1 for i in range(iters)])\n",
    "        d = d.transpose()\n",
    "        d = d.parallel_apply(lambda col: func_(col, m_cases, m_controls, FEATURES_COUNT, patient_ind, features_subset_size), axis=1)\n",
    "\n",
    "        \n",
    "        #         SAVE dataframe here!!!\n",
    "        d_to_write = d.to_frame()\n",
    "        d_to_write.columns = d_to_write.columns.astype(str)\n",
    "        \n",
    "        #./date/(fvl|res)/(iterations)/(features_subset_size)/(subset)/patient_id(absolute in whole dataset).\n",
    "        #i.e. ./18_10_2020/fvl/200000/15/2/13.parquet\n",
    "        \n",
    "        path = './{}/{}/{}/{}/{}'.format(DATE, KIND, iters, features_subset_size, subset)\n",
    "        Path(path).mkdir(parents=True, exist_ok=True)\n",
    "        d_to_write.to_parquet(path + '/{}.parquet'.format(ind_row[0]))\n",
    "        print(\"Result ready for k = \", features_subset_size, \", patient = \", ind_row[0], \"...\")\n",
    "\n",
    "        \n",
    "        # Obtain series from dataframe\n",
    "        d = pd.read_parquet(path + '/{}.parquet'.format(ind_row[0])).iloc[:,0]\n",
    "    \n",
    "        # collect results\n",
    "        feature_ind_vals = defaultdict(list)\n",
    "        d.apply(lambda row: collect_statistics(row,feature_ind_vals, features_subset_size))\n",
    "        feature_median = get_score(feature_ind_vals, feature_ind_to_name, all_measurements)\n",
    "        \n",
    "    all_measurements_medians = dict()\n",
    "    for feature_ind, vals in all_measurements.items():\n",
    "        median = np.median(vals)\n",
    "        if median > 0 and median != np.inf:\n",
    "            all_measurements_medians[feature_ind] = median\n",
    "    \n",
    "    selected_fs, iind_val = plot_dict(all_measurements_medians, feature_ind_to_name, \"median of all measurements; features_subset_size = \" + str(features_subset_size))\n",
    "    iind_median = np.median(iind_val)\n",
    "    selected_fs_reduced = list(map(lambda x: x[0],filter(lambda x: x[1] >= iind_median, zip(selected_fs, iind_val))))\n",
    "    \n",
    "    if selected_fs_reduced:\n",
    "        print(\"Selected features count: \", len(selected_fs_reduced))\n",
    "        print(selected_fs_reduced)\n",
    "    else:\n",
    "        print(\"selected_fs_reduced was empty for k = \", features_subset_size)        \n",
    "        \n",
    "    end = time.time()\n",
    "    print('Elapsed: ', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection and classification benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 10\n",
    "ITERATIONS=50\n",
    "FEATURES_SUBSET_SIZE=10\n",
    "TARGET='PATIENT'\n",
    "CASE='case'\n",
    "CONTROL='control'\n",
    "DATE = '18_10_2020'\n",
    "\n",
    "# CHANGE FOR EACH NOTEBOOK\n",
    "SUBSET = 0 #in range 0 to N_SPLITS-1\n",
    "KIND = 'fvl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector:\n",
    "    \"\"\"Extracts subset of most informative features and provides rank of all features from train samples.\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.features = features\n",
    "        \n",
    "    def get_features_rank():\n",
    "        return self.features_rank\n",
    "    \n",
    "    def get_features_subset():\n",
    "        return self.features_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestSelector(FeatureSelector):\n",
    "    def __init__(self, n_estimators=200):\n",
    "        super().__init__('RandomForestSelector')\n",
    "        self.forest = ExtraTreesClassifier(n_estimators=n_estimators, random_state=RANDOM_STATE)\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.forest.fit(X_train, y_train)\n",
    "        \n",
    "    def get_rank(self):\n",
    "        return self.forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectorsAggregator:\n",
    "    \"\"\"Aggregates partial feature selections obtained from FeatureSelectors.\"\"\"\n",
    "    def __init__(self, feature_selectors):\n",
    "        self.name = 'FeatureSelectorsAggregator'\n",
    "        self.feature_selectors = feature_selectors\n",
    "        \n",
    "    def get_features_rank(self):\n",
    "        return self.features_rank\n",
    "    \n",
    "    def get_features_subset(self):\n",
    "        return self.features_subset\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        for f_selector in self.feature_selectors:\n",
    "            f_selector.fit(X_train, y_train)\n",
    "    \n",
    "    def get_ranks(self):\n",
    "        ranks = []\n",
    "        for f_selector in self.feature_selectors:\n",
    "            ranks.append(f_selector.get_rank())\n",
    "        return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVEvaluator:\n",
    "    \"\"\"Evaluate performance of feature selection and classification model with leave-one-out cross validation\n",
    "        with n subsets (folds) of the whole dataset. For each iteration find the best classificator\n",
    "        for current train/test split by performing GridSearchCV on the current train data and asses its performance\n",
    "        on current test set. The results for each split are averaged and are the approximation of the performance\n",
    "        of the final model.\n",
    "            \n",
    "        If n = 1, the best model is created by selecting features with FeatureSelectorsAggregator\n",
    "        and performing GridSearchCV on the whole dataset to find the most accurate/sensitive classifier.\n",
    "        \"\"\"\n",
    "    def __init__(self, n_splits, fs_aggregator, labels, features, data, kind):\n",
    "        \"\"\"\n",
    "        Init CVEvaluator.\n",
    "\n",
    "        Args:\n",
    "            n_splits: Number of subsets.\n",
    "            fs_aggregator: FeatureSelectorsAggregator for feature selection at each split.\n",
    "            labels: list of strings representing labels.\n",
    "            features: list of feature names. Must match count of colums in data dataframe.\n",
    "            data: Pandas dataframe containing samples in rows with len(features) columns each.\n",
    "            kind: healthy, fvl, res.\n",
    "        \"\"\"\n",
    "        self.n_splits = n_splits\n",
    "        self.fs_aggregator = fs_aggregator\n",
    "        self.labels = labels\n",
    "        self.features = features\n",
    "        self.data = data\n",
    "        self.kind = kind\n",
    "        \n",
    "    def perform_evaluation(self, subset, iterations, features_subset_size):\n",
    "        skf = StratifiedKFold(n_splits=self.n_splits, random_state=RANDOM_STATE, shuffle=True)\n",
    "        train_index, test_index = list(skf.split(self.data, self.labels))[subset]\n",
    "        X_train, X_test = self.data[self.data.index.isin(train_index)], self.data[self.data.index.isin(test_index)]\n",
    "        y_train, y_test = [self.labels[i] for i in train_index], [self.labels[i] for i in test_index]        \n",
    "        X_train[TARGET] = y_train\n",
    "\n",
    "        m_cases = X_train[X_train[TARGET] == CASE]\n",
    "        m_controls = X_train[X_train[TARGET] == CONTROL]\n",
    "        del m_cases[TARGET]\n",
    "        del m_controls[TARGET]\n",
    "        \n",
    "        info_based(m_cases, m_controls, features_subset_size, iterations, subset)\n",
    "            \n",
    "#             self.fs_aggregator.fit(X_train, y_train)\n",
    "#             print(\"Another rank:\", len(self.fs_aggregator.get_ranks()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/hcl/{}.csv'.format(KIND), index_col=0)\n",
    "labels = list(df[TARGET].values)\n",
    "\n",
    "del df[TARGET]\n",
    "features = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_evaluator = CVEvaluator(N_SPLITS, None, labels, features, df, KIND)\n",
    "cv_evaluator.perform_evaluation(SUBSET, ITERATIONS, FEATURES_SUBSET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
